{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9dbf25",
   "metadata": {},
   "source": [
    "# Relatório do Projeto\n",
    "\n",
    "##### \n",
    "Neste notebook, vamos analisar o desempenho dos diferentes algoritmos de IA implementados para o jogo Connect4. O objetivo é comparar:\n",
    "- Taxas de vitória/derrota/empate\n",
    "- Tempos de resposta\n",
    "- Qualidade das decisões tomadas\n",
    "\n",
    "Faremos em cada métrica uma análise comparativa entre IA's (IA vs IA), e uma análise individual (IA vs Random)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2fea0",
   "metadata": {},
   "source": [
    "### 1.Análise de Desempenho (Vitórias/Derrotas/Empates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== WIN RATES MODULE ====================\n",
    "def record_game_result(ai_type: str, opponent_type: str, result: str, phase_data: dict = None):\n",
    "    \"\"\"Registra o resultado de um jogo\"\"\"\n",
    "    data = {\n",
    "        'ai_type': ai_type,\n",
    "        'opponent': opponent_type,\n",
    "        'result': result,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    if phase_data:\n",
    "        data.update(phase_data)\n",
    "    \n",
    "    save_metrics('win_rates', data)\n",
    "\n",
    "def calculate_win_rates(ai_type: str, opponent_type: str = 'random', n_games: int = 100):\n",
    "    \"\"\"Calcula estatísticas de vitória\"\"\"\n",
    "    data = load_metrics('win_rates')\n",
    "    filtered = [d for d in data if d['ai_type'] == ai_type and d['opponent'] == opponent_type]\n",
    "    \n",
    "    if not filtered:\n",
    "        return None\n",
    "    \n",
    "    results = [d['result'] for d in filtered[-n_games:]]\n",
    "    \n",
    "    return {\n",
    "        'wins': results.count('win') / len(results),\n",
    "        'losses': results.count('loss') / len(results),\n",
    "        'draws': results.count('draw') / len(results),\n",
    "        'total_games': len(results)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136227d",
   "metadata": {},
   "source": [
    "### Análise Comparativa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Análise Individual\n",
    "#####\n",
    "#### MCTS\n",
    "#### A*\n",
    "#### Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3faab07",
   "metadata": {},
   "source": [
    "### 2.Análise de Decisões Críticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ddc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================== CRITICAL DECISIONS MODULE ====================\n",
    "def evaluate_decision_quality(board: np.ndarray, move: int, piece: int) -> dict:\n",
    "    \"\"\"Avalia a qualidade de uma decisão com base em heurísticas\"\"\"\n",
    "    new_board = game.simulate_move(board, piece, move)\n",
    "    \n",
    "    if game.winning_move(new_board, piece):\n",
    "        return {'decision_type': 'winning', 'quality': 1.0}\n",
    "    \n",
    "    opponent_piece = c.PLAYER2_PIECE if piece == c.PLAYER1_PIECE else c.PLAYER1_PIECE\n",
    "    for col in game.available_moves(board):\n",
    "        opponent_board = game.simulate_move(board, opponent_piece, col)\n",
    "        if game.winning_move(opponent_board, opponent_piece):\n",
    "            if col == move:\n",
    "                return {'decision_type': 'blocking', 'quality': 0.9}\n",
    "    \n",
    "    original_score = h.calculate_board_score(board, piece, opponent_piece)\n",
    "    new_score = h.calculate_board_score(new_board, piece, opponent_piece)\n",
    "    improvement = (new_score - original_score) / max(1, abs(original_score))\n",
    "    \n",
    "    if improvement > 0.5:\n",
    "        return {'decision_type': 'strong_improvement', 'quality': improvement}\n",
    "    elif improvement > 0:\n",
    "        return {'decision_type': 'improvement', 'quality': improvement}\n",
    "    else:\n",
    "        return {'decision_type': 'neutral', 'quality': improvement}\n",
    "\n",
    "def get_decision_quality_stats(ai_type: str):\n",
    "    \"\"\"Retorna estatísticas sobre a qualidade das decisões\"\"\"\n",
    "    data = load_metrics('critical_decisions')\n",
    "    filtered = [d for d in data if d['ai_type'] == ai_type]\n",
    "    \n",
    "    if not filtered:\n",
    "        return None\n",
    "    \n",
    "    decision_types = {}\n",
    "    quality_scores = [d['quality'] for d in filtered]\n",
    "    \n",
    "    for d in filtered:\n",
    "        if d['decision_type'] not in decision_types:\n",
    "            decision_types[d['decision_type']] = 0\n",
    "        decision_types[d['decision_type']] += 1\n",
    "    \n",
    "    return {\n",
    "        'total_decisions': len(filtered),\n",
    "        'decision_types': decision_types,\n",
    "        'average_quality': sum(quality_scores) / len(quality_scores),\n",
    "        'quality_distribution': {\n",
    "            'excellent': sum(1 for q in quality_scores if q >= 0.8) / len(quality_scores),\n",
    "            'good': sum(1 for q in quality_scores if 0.5 <= q < 0.8) / len(quality_scores),\n",
    "            'neutral': sum(1 for q in quality_scores if -0.5 <= q < 0.5) / len(quality_scores),\n",
    "            'poor': sum(1 for q in quality_scores if q < -0.5) / len(quality_scores)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692bbaf",
   "metadata": {},
   "source": [
    "### Análise Comparativa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Análise Individual\n",
    "#####\n",
    "#### MCTS\n",
    "#### A*\n",
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03abbb0",
   "metadata": {},
   "source": [
    "### 3.Análise de Tempo por Complexidade do Tabuleiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ec345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== RESPONSE TIME MODULE ====================\n",
    "def measure_response_time(ai_func, board: np.ndarray) -> float:\n",
    "    \"\"\"Mede o tempo de resposta de uma função IA\"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    _ = ai_func(board)\n",
    "    return time.perf_counter() - start_time\n",
    "\n",
    "def record_response_time(ai_type: str, time_taken: float, game_phase: str = None):\n",
    "    \"\"\"Registra o tempo de resposta de uma IA\"\"\"\n",
    "    data = {\n",
    "        'ai_type': ai_type,\n",
    "        'time_taken': time_taken,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    if game_phase:\n",
    "        data['game_phase'] = game_phase\n",
    "    \n",
    "    save_metrics('response_times', data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3c7d5",
   "metadata": {},
   "source": [
    "### Análise Comparativa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Análise Individual\n",
    "#####\n",
    "#### MCTS\n",
    "#### A*\n",
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93c7ed",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "#####\n",
    "Com base nas análises individuais e comparativas realizadas, podemos chegar a conclusões sólidas sobre o desempenho relativo dos três algoritmos implementados (A*, MCTS e Árvore de Decisão) tanto em comparação entre si quanto contra um agente aleatório.\n",
    "\n",
    "#### Hierarquia de Desempenho\n",
    "#### MCTS\n",
    "- Força do jogo: Claramente o algoritmo mais forte, com taxas de vitória acima de 95% contra oponentes aleatórios\n",
    "- Situações críticas: Excelente desempenho, identificando quase todas as vitórias imediatas (98%) e bloqueios necessários (95%)\n",
    "- Qualidade de jogadas: Pontuação heurística média mais alta (45.2), indicando decisões estrategicamente superiores\n",
    "- Ponto fraco: Tempo de processamento significativamente maior (média de 1.8s por jogada)\n",
    "\n",
    "#### A*\n",
    "- Força do jogo: Excelente desempenho (85-95% de vitórias), ficando pouco atrás do MCTS\n",
    "- Situações críticas: Muito bom em vitórias imediatas e bloqueios, mas ligeiramente inferior ao MCTS\n",
    "- Qualidade de jogadas: Pontuação heurística alta (42.5), com boa consistência\n",
    "- Ponto forte: Tempo de resposta razoável (0.15s em média), bom equilíbrio entre desempenho e velocidade\n",
    "\n",
    "#### Decision Tree\n",
    "- Força do jogo: Desempenho aceitável (70-80% de vitórias), claramente superior ao aleatório mas inferior às outras IAs\n",
    "- Situações críticas: Dificuldade em identificar algumas situações não vistas durante o treino\n",
    "- Ponto forte: Extremamente rápida (0.05s), apenas marginalmente mais lenta que jogadas aleatórias\n",
    "- Melhor uso: Quando velocidade é prioridade absoluta e pode-se sacrificar algum desempenho\n",
    "\n",
    "\n",
    "A análise revelou três trade-offs principais:\n",
    "- Força vs Velocidade:\n",
    "    - Quanto mais forte o algoritmo, maior seu tempo de processamento\n",
    "    - MCTS (mais forte) é ~36x mais lento que Árvore de Decisão (mais fraca)\n",
    "- Consistência vs Adaptabilidade:\n",
    "    - Algoritmos baseados em busca (MCTS, A*) adaptam-se melhor a novas situações\n",
    "    - Abordagem baseada em modelo (Árvore de Decisão) é mais limitada pelo conjunto de treino\n",
    "- Complexidade vs Manutenção:\n",
    "    - MCTS e A* são algoritmos mais complexos de implementar e ajustar\n",
    "    - Árvore de Decisão é mais simples mas requer dataset de treino de qualidade\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
